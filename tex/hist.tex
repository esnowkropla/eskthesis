\chapter{Development of Adiabatic Quantum Computing}
\section{Feynman to Shor}
The initial idea of using quantum mechanics to carry out computation is usually attributed to Feynman.\cite{feynman}  He noticed the difficulty in simulating quantum mechanics on classical computers due to the exponential resources required, and proposed using quantum mechanics to build a computer that could simulate physics.

Quantum computing is usually described using the so-called gate model.\cite{qc}  Some initial register of qubits is prepared, and then acted on sequentially by unitary operators known as quantum gates (since unitary matrices are reversible, consequently quantum algorithms must be reversible).  This sequence of quantum gates results in the input register of qubits being put into some sort of quantum state, generally a mixture of superposition and entanglement.  Finally the qubits are measured, resulting in a classical vector of information out depending on which wave-function components are picked out by the measurement.  The number of gates required to go from the specified input to the desired output maps analogously to the number of classical gates required for a classical digital computation, and in the same way that counting classical gates allows us to form big-O asymptotic bounds on computation time we can asymptotically bound the running time of a quantum algorithm by counting the number of unitary gates it requires.

Interest in quantum computers expanded with the discovery of an algorithm that was provably asymptotically faster than any classical algorithm: the Deutsch-Josza algorithm.\cite{deutsch}  The Deutsch-Jozsa algorithm solves a highly contrived problem: given input that is guaranteed to be either equally partitioned between zeros and ones (balanced), OR contains all zeros OR all ones (constant), determine whether the input is balanced or constant.  Nonetheless the fastest classical algorithm is to simply inspect half of the elements plus one, $2^{n-1} + 1$ operations; meanwhile, the Deutsch-Josza algorithm can determine whether the input is balanced or constant in only a constant number of operations.  The quantum version is thus asymptotically faster than the classical version.

The discovery of a quantum algorithm asymptotically faster than the best classical one led to a surge of research, resulting in the discoveries of the Quantum Fourier Transform (QFT)\cite{qcbook}, Shor's\cite{shor} Algorithm and Grover's Algorithm\cite{grover}.

DETAILED SHOR'S ALGO GOES HERE

\section{Development of AQC}
The idea of expanding simulated annealing to include quantum effects to solve problems was initially introduced by Kadowaki and Nishimori.\cite{transverse}  The linking of quantum annealing to quantum computation was done slightly later by Farhi et. al in 2000.\cite{farhi}  The structure of AQC appears here entirely intact: evolving from easily prepared initial Hamiltonians into problem Hamiltonians via the adiabatic theorem.  What \cite{farhi} lacks are any experimental or theoretical arguments for the speed of AQC, or comparison to gate model quantum computing.  Farhi et. al. followed up with another paper\cite{farhi2} with some preliminary simulations of AQC carried out by numerically integrating Schr\"odinger's Equation.  These results seemed to indicate exponential speedup over classical algorithms for an NP-Complete problem, but due to the difficulty of simulating quantum mechanics on a classical computer the maximum problem size they could experiment with was quite small so they could not draw very broad conclusions.

After this hopeful initial result it was shown by van Dam et. al.\cite{vandam} that, at least in principle, AQC is equivalent to gate model quantum computing. 
