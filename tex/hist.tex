\chapter{A Brief History of AQC}
The idea of expanding simulated annealing to include quantum effects to solve problems was initially introduced by Kadowaki and Nishimori.\cite{transverse}  The linking of quantum annealing to quantum computation was done slightly later by Farhi et. al in 2000.\cite{farhi}  The structure of AQC appears here entirely intact: evolving from easily prepared initial Hamiltonians into problem Hamiltonians via the adiabatic theorem.  Farhi et. al.\cite{farhi} lacks any experimental or theoretical arguments for the speed of AQC, or comparison to gate model quantum computing.  Farhi et. al. followed up with another paper\cite{farhi2} with some preliminary simulations of AQC carried out by numerically integrating Schr\"odinger's Equation.  These results seemed to indicate exponential speedup over classical algorithms for an NP-Complete problem, but due to the difficulty of simulating quantum mechanics on a classical computer the maximum problem size they could experiment with was quite small so they could not draw very broad conclusions.

After this hopeful initial result it was shown by van Dam et. al.\cite{vandam} that, at least in principle, AQC is equivalent to gate model quantum computing.  Specifically they showed that adiabatic evolution taking time $T$ may be approximated by $O(T^2)$ unitary transformations of $n$ qubits.  However, van Dam et. al. also designed a class of minimization problems for which AQC has an exponential lower bound.  This was one of the earliest results in a controversy which continues to this day: how powerful are adiabatic quantum computers?  Proposed answers have included: being \emph{more} powerful than gate-model quantum computers, being able to solve NP-Complete problems efficiently; \emph{as} powerful as gate-model quantum computers; or no more powerful than classical computers.  Care must be taken to distinguish the questions of how powerful adiabatic quantum \emph{computing} is, and how powerful a \emph{given} adiabatic quantum computer is.

More papers on this topic followed, including several from A. P. Young with others.\cite{young3}\cite{young2}\cite{young1}  Using Quantum Monte Carlo techniques, they were able to increase the size of analyzable Hamiltonians from 24 spins to 256 spins.  They did this by simulating an effective classical model in imaginary time via a Wick rotation, for which the auto-correlation function for a spin is
\begin{equation}
	C(\tau) = q + \sum_n A_n \exp[-(E_n - E_0)\tau]
\end{equation}
where the sum is over the energy levels $n$, the $A_n$ are constants, q is the long time limit of the correlation function, and $\tau$ is imaginary time.  At large $\tau$ values the sum is dominated by the $E_1 - E_0$ term, which is to say the energy gap.  Fitting the auto-correlation function at long $\tau$s then allows extraction of the gap.\cite{young1}
Their results seemed to indicate the gap scaling exponentially with Hamiltonian size, characteristic of a first-order phase transition in the spin glass parameter.\cite{young2}

Concurrent with this effort to characterize adiabatic quantum computers theoretically was an effort to build one.  Beginning with a single qubit\cite{qubit}, scaling to eight\cite{PhysRevB.82.024511} and then 128\cite{boixo2} and 512.\cite{pudenz}  While entanglement has been demonstrated to occur inside of this machine\cite{lanting}, the evidence for a quantum speedup is mixed,\cite{pudenz}\cite{boixo}\cite{smolin} with a very recent paper by R{\o}nnow et. al. suggesting that the \texttt{VESUVIUS} machine (as the 512 spin machine is called) is not asymptotically faster than a classical computer.

In this work we carried out a variety of benchmarking on the \texttt{VESUVIUS} machine both to hopefully shed some light on the question of the speedup particular to this individual machine, and to validate out approach to problem compilation for AQC.
